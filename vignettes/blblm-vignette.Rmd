---
title: "blblm-vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{blblm-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

#blblm
This blblm package is used to implement a bag of little bootstraps for linear regression model. In thie documentation, I will be using the dataset `mtcars` to illustrate examples. Here are some definitions:

```{r}
# formula: represents the formula of choice - linear regression with weight in this case.
# data: data of choice
# B: a posive integer. It represents a number of bootstrap samples.
# ncpu: set as 1 in default which means the algorithm is implementing 1 CPU. The user can input any number of CPUs they would like to use.
# m: a positive number, the number of items to choose from.
```

```{r setup}
library(blblm)
fit_parallelization <- blblm(mpg ~ wt * hp, data = mtcars, m = 3, B = 100, 4)
#example we'll be using in this vignette. 
usethis::use_package("tidyr", type = "suggest")
```

There are two main options to run this blblm package: run with one CPU, which is a default, and the other way with multiple CPUs of the user's choice. To implement parallelization for users using multiple CPUs, `future_map` along with `plan()` were implemented in the main `blblm` function as well as the `blblm_mean` function. The user can decide the nunber of CPUs they use by either choosing to leave the last parameter of the `blblm` function, `ncpu`, as default which is 1 (no parallelization) OR input a positive integer which would be the number of CPUs that will be used. 

The parallelization option is more efficient where with a sample of 100,000 bootstrap sample run time is almost half of the function without. Below is a system time of the blblm function when parallelization was  implemented with 4 CPUs and 10,000 bootstraps samples:
```{r}
system.time(blblm(mpg ~ wt * hp, data = mtcars, m = 5, B = 10000, 2))
```

```{r}
system.time(blblm(mpg ~ wt * hp, data = mtcars, m = 5, B = 10000, 4))
```

```{r}
system.time(blblm(mpg ~ wt * hp, data = mtcars, m = 5, B = 10000, 6))
```


Compare the results above to a function where 1 CPU was implemented with no parallelization:
```{r}
system.time(blblm(mpg ~ wt * hp, data = mtcars, m = 5, B = 10000))
```
As can be shown, the system time is shorter when multiple CPUs were implemented compared to when only one CPU was used by almost a half. 

Going more in-depth about the `blblm` package, it takes the formula (such as linear regression formula), data the user is using, the number of items to choose from when we take the sample integer, number of bootstraps, and number of CPU(s) the user decides to use. If the user decides to use only 1 CPU, the function runs the following code:

```{r}
#estimates <- map(
#  data_list,
#  ~ lm_each_subsample(formula = formula, data = ., n = nrow(data), B = B))
#res <- list(estimates = estimates, formula = formula)
```

If the user decides to use multiple CPU, the function runs the following code. As can be seen, is uses the `future_map` function of `furrr` package. It uses `suppressWarnings(plan(multiprocess, workers = ncpu))` to determine how many CPUs are being used:
```{r}
#estimates <- future_map(
#      data_list,
#      ~ lm_each_subsample(formula = formula, data = ., n = nrow(data), B = B))
#res <- future_map(
#      data_list,
#      ~ list(estimates = estimates, formula = formula)
#    )
```

Here, `lm_each_subsample` is a formula that compute the bootstraps of regression estimates of blb data. It drops the original closure of formula and assign a new variable for bootstrapping. 
```{r}
#lm_each_subsample <- function(formula, data, n, B) {
#  environment(formula) <- environment()
#  m <- model.frame(formula, data)
#  X <- model.matrix(formula, m)
#  y <- model.response(m)
#  replicate(B, lm1(X, y, n), simplify = FALSE)
#}
```

One of the main functions that summarizes the results is this `lm1` function below. This function takes other two functions `blbcoef` and `blbsigma` which will be discussed further later. This function computes a linear regression with weight (freq) 
```{r}
#lm1 <- function(X, y, n) {
#  freqs <- as.vector(rmultinom(1, n, rep(1, nrow(X))))
#  fit <- lm.wfit(X, y, freqs)
#  list(coef = blbcoef(fit), sigma = blbsigma(fit))
#}
```

`blbcoef` and `blbsigma` compute the coefficient and the sigma of the model we are fitting, in this example a linear regression with weight. 
```{r}
#blbcoef <- function(fit) {
#  coef(fit)
#}

#blbsigma <- function(fit) {
#  p <- fit$rank
#  e <- fit$residuals
#  w <- fit$weights
#  sqrt(sum(w * (e^2)) / (sum(w) - p))
#}
```

Here is an example of using `coef`.
```{r}
print(coef(fit_parallelization))
```
Here is an example of using `sigma`
```{r}
print(sigma(fit_parallelization))
```

`sigma` also has an option to add a 0.95 confidence interval's upper and lower limits
```{r}
print(sigma(fit_parallelization, confidence = TRUE))
```

`confint` is a function that returns the 95% confidence interval by default. The user can also change it to a different confidence interval by defining `level`. 
```{r}
#confint.blblm <- function(object, parm = NULL, level = 0.95, ncpu = 1,...) {
#  if (is.null(parm)) {
#    parm <- attr(terms(object$formula), "term.labels")
#  }
#  alpha <- 1 - level
#  est <- object$estimates
#  out <- map_rbind(parm, function(p) {
#    map_mean(est, ~ map_dbl(., list("coef", p)) %>% quantile(c(alpha / 2, 1 - alpha / 2)), ncpu)
#  })
#  if (is.vector(out)) {
#    out <- as.matrix(t(out))
#  }
#  dimnames(out)[[1]] <- parm
#  out
#}
```

Here is an example using `confint`. 
```{r}
confint(fit_parallelization, c("wt", "hp"))
```
The last function is `predict` which makes predictions. 
```{r}
#predict.blblm <- function(object, new_data, confidence = FALSE, level = 0.95, ncpu = 1, ...) {
#  est <- object$estimates
#  X <- model.matrix(reformulate(attr(terms(object$formula), "term.labels")), new_data)
#  if (confidence) {
#    map_mean(est, ~ map_cbind(., ~ X %*% .$coef) %>%
#               apply(1, mean_lwr_upr, level = level) %>%
#               t(), ncpu)
#  } else {
#    map_mean(est, ~ map_cbind(., ~ X %*% .$coef) %>% rowMeans(), ncpu)
#  }
#}
```

Here is an example of using `predict`.
```{r}
predict(fit_parallelization, data.frame(wt = c(2.5, 3), hp = c(150, 170)))
```

#blblogreg


